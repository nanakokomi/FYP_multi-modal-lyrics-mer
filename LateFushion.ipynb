{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packagage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the torch package\n",
    "#%pip install torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from data import merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and drop VADER columns\n",
    "df_train = pd.read_csv('data/merged/merged_cleaned_sentiment_train.csv').drop(['pos','neg','neu', 'compound'], axis = 1)\n",
    "df_val = pd.read_csv('data/merged/merged_cleaned_sentiment_validation.csv').drop(['pos','neg','neu', 'compound'], axis = 1)\n",
    "df_test = pd.read_csv('data/merged/merged_cleaned_sentiment_test.csv').drop(['pos','neg','neu', 'compound'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save audio features\n",
    "# 5 audio features + 2 real target\n",
    "df_train = df_train[[ 'y_valence', 'y_arousal']]\n",
    "df_val = df_val[[ 'y_valence', 'y_arousal']]\n",
    "df_test = df_test[['y_valence', 'y_arousal']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lyrics features and merge with audio\n",
    "df_train = pd.concat([df_train, pd.read_csv('data/lyrics/lyrics_features_train.csv').iloc[:, :-200]], axis=1)\n",
    "df_val = pd.concat([df_val, pd.read_csv('data/lyrics/lyrics_features_val.csv').iloc[:, :-200]], axis=1)\n",
    "df_test = pd.concat([df_test, pd.read_csv('data/lyrics/lyrics_features_test.csv').iloc[:, :-200]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values from the training, validation, and test datasets\n",
    "df_train = df_train.dropna()\n",
    "df_val = df_val.dropna()\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['Unnamed: 0'])\n",
    "df_val = df_val.drop(columns=['Unnamed: 0'])\n",
    "df_test = df_test.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y_valence', 'y_arousal', 'pos', 'neg', 'neu', 'compound',\n",
       "       'tfidf_pca_1', 'tfidf_pca_2', 'tfidf_pca_3', 'tfidf_pca_4',\n",
       "       ...\n",
       "       'tfidf_pca_91', 'tfidf_pca_92', 'tfidf_pca_93', 'tfidf_pca_94',\n",
       "       'tfidf_pca_95', 'tfidf_pca_96', 'tfidf_pca_97', 'tfidf_pca_98',\n",
       "       'tfidf_pca_99', 'tfidf_pca_100'],\n",
       "      dtype='object', length=106)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output colums\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training set\n",
    "# X_train: Features for training set, excluding the target variables 'y_valence' and 'y_arousal'\n",
    "X_train = df_train.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "# y_train_valence: Target variable 'y_valence' for training set\n",
    "y_train_valence = df_train.y_valence.values \n",
    "# y_train_arousal: Target variable 'y_arousal' for training set\n",
    "y_train_arousal = df_train.y_arousal.values\n",
    "    \n",
    "# Validation set\n",
    "# X_val: Features for validation set, excluding the target variables 'y_valence' and 'y_arousal'\n",
    "X_val = df_val.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "# y_val_valence: Target variable 'y_valence' for validation set\n",
    "y_val_valence = df_val.y_valence.values \n",
    "# y_val_arousal: Target variable 'y_arousal' for validation set\n",
    "y_val_arousal = df_val.y_arousal.values \n",
    "\n",
    "# Test set\n",
    "# X_test: Features for test set, excluding the target variables 'y_valence' and 'y_arousal'\n",
    "X_test = df_test.drop(['y_valence', 'y_arousal'], axis=1).values\n",
    "# y_test_valence: Target variable 'y_valence' for test set\n",
    "y_test_valence = df_test.y_valence.values \n",
    "# y_test_arousal: Target variable 'y_arousal' for test set\n",
    "y_test_arousal = df_test.y_arousal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['y_valence', 'y_arousal', 'pos', 'neg', 'neu', 'compound',\n",
      "       'tfidf_pca_1', 'tfidf_pca_2', 'tfidf_pca_3', 'tfidf_pca_4',\n",
      "       ...\n",
      "       'tfidf_pca_91', 'tfidf_pca_92', 'tfidf_pca_93', 'tfidf_pca_94',\n",
      "       'tfidf_pca_95', 'tfidf_pca_96', 'tfidf_pca_97', 'tfidf_pca_98',\n",
      "       'tfidf_pca_99', 'tfidf_pca_100'],\n",
      "      dtype='object', length=106)\n"
     ]
    }
   ],
   "source": [
    "print(df_test.columns)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(X_val, y_1_validation, y_2_validation, model_predictions_file='predictions.csv'):\n",
    "    \"\"\"Evaluate the trained model using different evaluation criteria, including Normalized RMSE\"\"\"\n",
    "    \n",
    "    # Load the saved predictions from the CSV file\n",
    "    df_predictions = pd.read_csv(model_predictions_file)\n",
    "    \n",
    "    # Get the true values from validation data\n",
    "    true_valence = y_1_validation\n",
    "    true_arousal = y_2_validation\n",
    "\n",
    "    # Ensure predictions are in the original range (if necessary)\n",
    "    # If predictions are standardized, use the inverse_transform of your scaler before proceeding.\n",
    "    # Example: df_predictions['pred_valence'] = scaler.inverse_transform(df_predictions[['pred_valence']])\n",
    "\n",
    "    # Compute RMSE\n",
    "    rmse_valence = mean_squared_error(true_valence, df_predictions['pred_valence'], squared=False)\n",
    "    rmse_arousal = mean_squared_error(true_arousal, df_predictions['pred_arousal'], squared=False)\n",
    "\n",
    "    # Compute Normalized RMSE\n",
    "    valence_range = max(true_valence) - min(true_valence)\n",
    "    arousal_range = max(true_arousal) - min(true_arousal)\n",
    "\n",
    "    normalized_rmse_valence = rmse_valence / valence_range if valence_range > 0 else None\n",
    "    normalized_rmse_arousal = rmse_arousal / arousal_range if arousal_range > 0 else None\n",
    "\n",
    "    # Compute R¬≤\n",
    "    r2_valence = r2_score(true_valence, df_predictions['pred_valence'])\n",
    "    r2_arousal = r2_score(true_arousal, df_predictions['pred_arousal'])\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"RMSE for Valence: {rmse_valence:.4f}\")\n",
    "    print(f\"RMSE for Arousal: {rmse_arousal:.4f}\")\n",
    "    print(f\"Normalized RMSE for Valence: {normalized_rmse_valence:.4f}\" if normalized_rmse_valence is not None else \"Valence range is zero, cannot compute NRMSE.\")\n",
    "    print(f\"Normalized RMSE for Arousal: {normalized_rmse_arousal:.4f}\" if normalized_rmse_arousal is not None else \"Arousal range is zero, cannot compute NRMSE.\")\n",
    "    print(f\"R¬≤ for Valence: {r2_valence:.4f}\")\n",
    "    print(f\"R¬≤ for Arousal: {r2_arousal:.4f}\")\n",
    "    \n",
    "    # Return evaluation results as a dictionary\n",
    "    eval_results = {\n",
    "        'rmse_valence': rmse_valence,\n",
    "        'rmse_arousal': rmse_arousal,\n",
    "        'normalized_rmse_valence': normalized_rmse_valence,\n",
    "        'normalized_rmse_arousal': normalized_rmse_arousal,\n",
    "        'r2_valence': r2_valence,\n",
    "        'r2_arousal': r2_arousal\n",
    "    }\n",
    "\n",
    "    return eval_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization\n",
    "# Á¨¨‰∫åÊ≠•ÔºöÂΩí‰∏ÄÂåñÔºàüí° ËÆ≠ÁªÉÈõÜ fitÔºåval/test Âè™ transformÔºâ\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generic MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        in_features = input_size\n",
    "        for h in hidden_layer_sizes:\n",
    "            layers.append(nn.Linear(in_features, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_features = h\n",
    "        layers.append(nn.Linear(in_features, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for one model\n",
    "def train_single_mlp(X_train, y_train, hidden_layers, max_iter):\n",
    "    model = MLP(X_train.shape[1], hidden_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_tensor)\n",
    "        loss = criterion(outputs, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_torch(X, y_1, y_2, X_val, param_grid=None):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'hidden_layer_sizes': [(5,), (10,), (15,), (5,5), (10,10), (15,15)],\n",
    "            'max_iter': [500, 1000]\n",
    "        }\n",
    "\n",
    "    best_val_model = None\n",
    "    best_arou_model = None\n",
    "    best_val_score = float('inf')\n",
    "    best_arou_score = float('inf')\n",
    "    best_hidden_layers = None\n",
    "    best_max_iter = None\n",
    "\n",
    "    for hidden_layers, max_iter in product(param_grid['hidden_layer_sizes'], param_grid['max_iter']):\n",
    "        print(f\"üîç Trying config: hidden_layers={hidden_layers}, max_iter={max_iter}\")\n",
    "\n",
    "        model_val = train_single_mlp(X_scaled, y_1, hidden_layers, max_iter)\n",
    "        preds_val = model_val(torch.tensor(X_scaled, dtype=torch.float32)).detach().numpy().squeeze()\n",
    "        mse_val = mean_squared_error(y_1, preds_val)\n",
    "\n",
    "        if mse_val < best_val_score:\n",
    "            best_val_score = mse_val\n",
    "            best_val_model = model_val\n",
    "            best_hidden_layers = hidden_layers\n",
    "            best_max_iter = max_iter\n",
    "\n",
    "        model_arou = train_single_mlp(X_scaled, y_2, hidden_layers, max_iter)\n",
    "        preds_arou = model_arou(torch.tensor(X_scaled, dtype=torch.float32)).detach().numpy().squeeze()\n",
    "        mse_arou = mean_squared_error(y_2, preds_arou)\n",
    "\n",
    "        if mse_arou < best_arou_score:\n",
    "            best_arou_score = mse_arou\n",
    "            best_arou_model = model_arou\n",
    "\n",
    "    # Áî®ÊúÄ‰ºòÊ®°ÂûãÂú®È™åËØÅÈõÜ‰∏äÈ¢ÑÊµãÂπ∂‰øùÂ≠ò‰∏∫ CSVÔºà‰ªÖÈ™åËØÅÈõÜÔºâ\n",
    "    best_val_model.eval()\n",
    "    best_arou_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "        predictions_val = best_val_model(X_val_tensor).squeeze().numpy()\n",
    "        predictions_arou = best_arou_model(X_val_tensor).squeeze().numpy()\n",
    "\n",
    "    df_predictions = pd.DataFrame({\n",
    "        'pred_valence': predictions_val,\n",
    "        'pred_arousal': predictions_arou\n",
    "    })\n",
    "    #df_predictions.to_csv('csv/lyrics/Lyrics_predictions_mlp_torch.csv', index=False)\n",
    "\n",
    "    print(\"‚úÖ PyTorch MLP training completed and validation predictions saved.\")\n",
    "    return best_val_model, best_arou_model, scaler, best_hidden_layers, best_max_iter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions_torch(model_val, model_arou, X_test, scaler, output_filename):\n",
    "    \"\"\"\n",
    "    Áî® PyTorch Ê®°ÂûãÂØπÊµãËØïÈõÜ X_test ÂÅöÈ¢ÑÊµãÔºåÂπ∂‰øùÂ≠ò‰∏∫ CSV Êñá‰ª∂„ÄÇ\n",
    "\n",
    "    ÂèÇÊï∞Ôºö\n",
    "    - model_val: Â∑≤ËÆ≠ÁªÉÁöÑ valence Ê®°Âûã\n",
    "    - model_arou: Â∑≤ËÆ≠ÁªÉÁöÑ arousal Ê®°Âûã\n",
    "    - X_test: ÊµãËØïÈõÜËæìÂÖ•ÁâπÂæÅÔºàÊú™Áº©ÊîæÔºâ\n",
    "    - scaler: ÂíåËÆ≠ÁªÉÊó∂Áî®ÁöÑ‰∏ÄËá¥ÁöÑ MinMaxScaler\n",
    "    - output_filename: ‰øùÂ≠òÁªìÊûúÊñá‰ª∂Âêç\n",
    "    \"\"\"\n",
    "    import torch\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "    model_val.eval()\n",
    "    model_arou.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_val = model_val(X_test_tensor).squeeze().numpy()\n",
    "        preds_aro = model_arou(X_test_tensor).squeeze().numpy()\n",
    "\n",
    "    df_pred = pd.DataFrame({\n",
    "        \"pred_valence\": preds_val,\n",
    "        \"pred_arousal\": preds_aro\n",
    "    })\n",
    "    df_pred.to_csv(output_filename, index=False)\n",
    "    print(f\"‚úÖ Test predictions saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰ªéÊµãËØïÈõÜ DataFrame ‰∏≠ÊèêÂèñÁâπÂæÅÂàó\n",
    "X_test_lyrics = df_test.drop(['y_valence', 'y_arousal'], axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test predictions saved to csv/lyrics/lyrics_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate_test_predictions_torch(\n",
    "    best_val_model,\n",
    "    best_arou_model,\n",
    "    X_test_lyrics,\n",
    "    scaler,\n",
    "    \"csv/lyrics/lyrics_test_predictions.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Trying config: hidden_layers=(5,), max_iter=500\n",
      "üîç Trying config: hidden_layers=(5,), max_iter=1000\n",
      "üîç Trying config: hidden_layers=(10,), max_iter=500\n",
      "üîç Trying config: hidden_layers=(10,), max_iter=1000\n",
      "üîç Trying config: hidden_layers=(15,), max_iter=500\n",
      "üîç Trying config: hidden_layers=(15,), max_iter=1000\n",
      "üîç Trying config: hidden_layers=(5, 5), max_iter=500\n",
      "üîç Trying config: hidden_layers=(5, 5), max_iter=1000\n",
      "üîç Trying config: hidden_layers=(10, 10), max_iter=500\n",
      "üîç Trying config: hidden_layers=(10, 10), max_iter=1000\n",
      "üîç Trying config: hidden_layers=(15, 15), max_iter=500\n",
      "üîç Trying config: hidden_layers=(15, 15), max_iter=1000\n",
      "‚úÖ PyTorch MLP training completed and validation predictions saved.\n"
     ]
    }
   ],
   "source": [
    "best_val_model, best_arou_model, scaler, best_layers, best_iter = train_mlp_torch(\n",
    "    X_train, y_train_valence, y_train_arousal, X_val\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Valence: 0.9820\n",
      "RMSE for Arousal: 0.9683\n",
      "Normalized RMSE for Valence: 0.2820\n",
      "Normalized RMSE for Arousal: 0.1903\n",
      "R¬≤ for Valence: 0.1025\n",
      "R¬≤ for Arousal: -0.0370\n"
     ]
    }
   ],
   "source": [
    "results_scaled = evaluate_model(\n",
    "    X_val=X_val_scaled,\n",
    "    y_1_validation=y_val_valence,\n",
    "    y_2_validation=y_val_arousal,\n",
    "    model_predictions_file='csv/lyrics/Lyrics_predictions_mlp_torch.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
